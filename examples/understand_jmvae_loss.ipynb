{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.distributions as dist\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from scipy.stats import norm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example to show the effect of the flows and of the functions $f_i$ on the JMVAE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an artificial dataset with a 2D latent space\n",
    "\n",
    "# Fix the random seed\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "\n",
    "\n",
    "N = 10000\n",
    "x = dist.Normal(0,1).sample([N])\n",
    "y = dist.Normal(0,1).sample([N])\n",
    "print(x.shape)\n",
    "plt.scatter(x,y)\n",
    "data=[x,y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10000])\n"
     ]
    }
   ],
   "source": [
    "# We define the joint posterior to be a 2D gaussian with diagonal covariance matrix\n",
    "s1 = 0.1\n",
    "s2 = 0.1\n",
    "\n",
    "def sample_from_joint_posterior(x,y,K=1):\n",
    "    z1 = dist.Normal(x,s1).sample([K])\n",
    "    z2 = dist.Normal(y,s2).sample([K])\n",
    "    \n",
    "    return torch.stack([z1, z2])\n",
    "\n",
    "def sample_from_uni_posterior_x(x,K=1):\n",
    "    z1 = dist.Normal(x,s1).sample([K])\n",
    "    z2 = dist.Normal(0,np.sqrt(1+s2**2)).sample([K])\n",
    "    \n",
    "    return torch.stack([z1,z2])\n",
    "\n",
    "def sample_from_uni_posterior_y(y,K=1):\n",
    "    z1 = dist.Normal(0,np.sqrt(1+s1**2)).sample([K])\n",
    "    z2 = dist.Normal(y,s2).sample([K])\n",
    "    \n",
    "    return torch.stack([z1,z2])\n",
    "\n",
    "z1,z2 = sample_from_joint_posterior(x,y,K=100)\n",
    "print(z1.shape)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from bivae.my_pythae.models.vae_maf import my_VAE_MAF, VAE_MAF_Config\n",
    "from bivae.my_pythae.models.vae import my_VAE\n",
    "from pythae.models.vae import VAEConfig\n",
    "from pythae.models.nn.base_architectures import BaseDecoder, BaseEncoder\n",
    "from pythae.models.base.base_utils import ModelOutput\n",
    "\n",
    "n_hidden_dim = 100\n",
    "\n",
    "class Encoder_VAE_MLP(BaseEncoder):\n",
    "    def __init__(self, args: dict):\n",
    "        BaseEncoder.__init__(self)\n",
    "        self.input_dim = args.input_dim\n",
    "        self.latent_dim = args.latent_dim\n",
    "\n",
    "        layers = nn.ModuleList()\n",
    "\n",
    "        layers.append(nn.Sequential(nn.Linear(np.prod(args.input_dim), n_hidden_dim), nn.ReLU()))\n",
    "\n",
    "        self.layers = layers\n",
    "        self.depth = len(layers)\n",
    "\n",
    "        self.embedding = nn.Linear(n_hidden_dim, self.latent_dim)\n",
    "        self.log_var = nn.Linear(n_hidden_dim, self.latent_dim)\n",
    "\n",
    "    def forward(self, x, output_layer_levels = None):\n",
    "        output = ModelOutput()\n",
    "\n",
    "        max_depth = self.depth\n",
    "\n",
    "        if output_layer_levels is not None:\n",
    "\n",
    "            assert all(\n",
    "                self.depth >= levels > 0 or levels == -1\n",
    "                for levels in output_layer_levels\n",
    "            ), (\n",
    "                f\"Cannot output layer deeper than depth ({self.depth}). \"\n",
    "                f\"Got ({output_layer_levels}).\"\n",
    "            )\n",
    "\n",
    "            if -1 in output_layer_levels:\n",
    "                max_depth = self.depth\n",
    "            else:\n",
    "                max_depth = max(output_layer_levels)\n",
    "\n",
    "        out = x.reshape(-1, np.prod(self.input_dim))\n",
    "\n",
    "        for i in range(max_depth):\n",
    "            out = self.layers[i](out)\n",
    "\n",
    "            if output_layer_levels is not None:\n",
    "                if i + 1 in output_layer_levels:\n",
    "                    output[f\"embedding_layer_{i+1}\"] = out\n",
    "            if i + 1 == self.depth:\n",
    "                output[\"embedding\"] = self.embedding(out)\n",
    "                output[\"log_covariance\"] = self.log_var(out)\n",
    "\n",
    "        return output\n",
    "    \n",
    "class Decoder_AE_MLP(BaseDecoder):\n",
    "    def __init__(self, args: dict):\n",
    "        BaseDecoder.__init__(self)\n",
    "\n",
    "        self.input_dim = args.input_dim\n",
    "\n",
    "        # assert 0, np.prod(args.input_dim)\n",
    "\n",
    "        layers = nn.ModuleList()\n",
    "\n",
    "        layers.append(nn.Sequential(nn.Linear(args.latent_dim, n_hidden_dim), nn.ReLU()))\n",
    "\n",
    "        layers.append(\n",
    "            nn.Sequential(nn.Linear(n_hidden_dim, int(np.prod(args.input_dim))), nn.Sigmoid())\n",
    "        )\n",
    "\n",
    "        self.layers = layers\n",
    "        self.depth = len(layers)\n",
    "\n",
    "    def forward(self, z: torch.Tensor, output_layer_levels=None):\n",
    "\n",
    "        output = ModelOutput()\n",
    "\n",
    "        max_depth = self.depth\n",
    "\n",
    "        if output_layer_levels is not None:\n",
    "\n",
    "            assert all(\n",
    "                self.depth >= levels > 0 or levels == -1\n",
    "                for levels in output_layer_levels\n",
    "            ), (\n",
    "                f\"Cannot output layer deeper than depth ({self.depth}). \"\n",
    "                f\"Got ({output_layer_levels}).\"\n",
    "            )\n",
    "\n",
    "            if -1 in output_layer_levels:\n",
    "                max_depth = self.depth\n",
    "            else:\n",
    "                max_depth = max(output_layer_levels)\n",
    "\n",
    "        out = z\n",
    "\n",
    "        for i in range(max_depth):\n",
    "            out = self.layers[i](out)\n",
    "\n",
    "            if output_layer_levels is not None:\n",
    "                if i + 1 in output_layer_levels:\n",
    "                    output[f\"reconstruction_layer_{i+1}\"] = out\n",
    "            if i + 1 == self.depth:\n",
    "                output[\"reconstruction\"] = out.reshape((z.shape[0],) + self.input_dim)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "class my_model(nn.Module):\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        vae = my_VAE_MAF\n",
    "        vae_config = VAE_MAF_Config((1,1),latent_dim=2)\n",
    "        e1,e2 = Encoder_VAE_MLP(vae_config), Encoder_VAE_MLP(vae_config)\n",
    "        d1,d2 =Decoder_AE_MLP(vae_config), Decoder_AE_MLP(vae_config)\n",
    "        self.vaes = nn.ModuleList([\n",
    "            vae(model_config=vae_config, encoder=e1, decoder=d1),\n",
    "            vae(model_config=vae_config, encoder=e2, decoder=d2)\n",
    "\n",
    "        ])\n",
    "        \n",
    "    \n",
    "    def compute_kld(self, data):\n",
    "        \"\"\" Computes KL(q(z|x,y) || q(z|x)) + KL(q(z|x,y) || q(z|y))\"\"\"\n",
    "\n",
    "        z_xy=sample_from_joint_posterior(data[0],data[1]).squeeze(1).permute(1,0)\n",
    "        # print(z_xy.size())\n",
    "        reg = 0\n",
    "        details_reg = {}\n",
    "        for m, vae in enumerate(self.vaes):\n",
    "            # print(z_xy.shape)\n",
    "            flow_output = vae.flow(z_xy) if hasattr(vae, \"flow\") else vae.inverse_flow(z_xy)\n",
    "            vae_output = vae.encoder(data[m].unsqueeze(1))\n",
    "            mu, log_var, z0 = vae_output.embedding, vae_output.log_covariance, flow_output.out\n",
    "            log_q_z0 = (-0.5 * (log_var + np.log(2*np.pi) + torch.pow(z0 - mu, 2) / torch.exp(log_var))).sum(dim=1)\n",
    "\n",
    "            # kld -= log_q_z0 + flow_output.log_abs_det_jac\n",
    "            # details_reg[f'kld_{m}'] = qz_xy.sum() - (log_q_z0 + flow_output.log_abs_det_jac).sum()\n",
    "            details_reg[f'kld_{m}'] =  - (log_q_z0 + flow_output.log_abs_det_jac).sum()\n",
    "\n",
    "            reg += details_reg[f'kld_{m}']\n",
    "            \n",
    "        return reg, details_reg\n",
    "    \n",
    "    def sample_from_x(self, x, K=100):\n",
    "        \n",
    "        d = torch.stack([x]*K)\n",
    "        z = self.vaes[0](d).z\n",
    "        return z\n",
    "    \n",
    "    def sample_from_y(self, y, K=100):\n",
    "        d = torch.stack([y]*K)\n",
    "        z = self.vaes[1](d).z\n",
    "        return z\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n",
      "Epoch 0 : train_loss 6.962843451605902\n",
      "Epoch 0 : test_loss 6.830992065429688\n",
      "saved model\n",
      "Epoch 1 : train_loss 6.791622884114584\n",
      "Epoch 1 : test_loss 6.6606904296875\n",
      "saved model\n",
      "Epoch 2 : train_loss 6.611930962456597\n",
      "Epoch 2 : test_loss 6.506016357421875\n",
      "saved model\n",
      "Epoch 3 : train_loss 6.463098931206598\n",
      "Epoch 3 : test_loss 6.3498558349609375\n",
      "saved model\n",
      "Epoch 4 : train_loss 6.321701917860243\n",
      "Epoch 4 : test_loss 6.228921264648437\n",
      "saved model\n",
      "Epoch 5 : train_loss 6.21149016655816\n",
      "Epoch 5 : test_loss 6.145284484863281\n",
      "saved model\n",
      "Epoch 6 : train_loss 6.126471245659722\n",
      "Epoch 6 : test_loss 6.041126037597656\n",
      "saved model\n",
      "Epoch 7 : train_loss 6.0501984320746525\n",
      "Epoch 7 : test_loss 5.990611267089844\n",
      "saved model\n",
      "Epoch 8 : train_loss 5.996305460611979\n",
      "Epoch 8 : test_loss 5.951221862792969\n",
      "saved model\n",
      "Epoch 9 : train_loss 5.967364759657118\n",
      "Epoch 9 : test_loss 5.92538916015625\n",
      "saved model\n",
      "Epoch 10 : train_loss 5.936485039605035\n",
      "Epoch 10 : test_loss 5.887101135253906\n",
      "saved model\n",
      "Epoch 11 : train_loss 5.919546034071181\n",
      "Epoch 11 : test_loss 5.860193176269531\n",
      "saved model\n",
      "Epoch 12 : train_loss 5.899316528320313\n",
      "Epoch 12 : test_loss 5.854329833984375\n",
      "saved model\n",
      "Epoch 13 : train_loss 5.887372395833333\n",
      "Epoch 13 : test_loss 5.836351989746094\n",
      "saved model\n",
      "Epoch 14 : train_loss 5.873372504340278\n",
      "Epoch 14 : test_loss 5.810130310058594\n",
      "Epoch 15 : train_loss 5.855400675455729\n",
      "Epoch 15 : test_loss 5.8120730590820315\n",
      "saved model\n",
      "Epoch 16 : train_loss 5.831895521375868\n",
      "Epoch 16 : test_loss 5.7653720092773435\n",
      "saved model\n",
      "Epoch 17 : train_loss 5.808888319227431\n",
      "Epoch 17 : test_loss 5.759743041992188\n",
      "saved model\n",
      "Epoch 18 : train_loss 5.7832211507161455\n",
      "Epoch 18 : test_loss 5.73024951171875\n",
      "saved model\n",
      "Epoch 19 : train_loss 5.759069742838542\n",
      "Epoch 19 : test_loss 5.699439697265625\n",
      "saved model\n",
      "Epoch 20 : train_loss 5.717593221028646\n",
      "Epoch 20 : test_loss 5.6682392578125\n",
      "saved model\n",
      "Epoch 21 : train_loss 5.693960272894965\n",
      "Epoch 21 : test_loss 5.6356640625\n",
      "saved model\n",
      "Epoch 22 : train_loss 5.658587415907118\n",
      "Epoch 22 : test_loss 5.608702331542969\n",
      "saved model\n",
      "Epoch 23 : train_loss 5.620909559461806\n",
      "Epoch 23 : test_loss 5.555483764648438\n",
      "saved model\n",
      "Epoch 24 : train_loss 5.5888427734375\n",
      "Epoch 24 : test_loss 5.528430541992187\n",
      "saved model\n",
      "Epoch 25 : train_loss 5.553322998046875\n",
      "Epoch 25 : test_loss 5.493742919921875\n",
      "saved model\n",
      "Epoch 26 : train_loss 5.521428276909722\n",
      "Epoch 26 : test_loss 5.469413818359375\n",
      "saved model\n",
      "Epoch 27 : train_loss 5.482338636610243\n",
      "Epoch 27 : test_loss 5.429801147460937\n",
      "saved model\n",
      "Epoch 28 : train_loss 5.450626925998264\n",
      "Epoch 28 : test_loss 5.409153442382813\n",
      "saved model\n",
      "Epoch 29 : train_loss 5.419139553493924\n",
      "Epoch 29 : test_loss 5.35615380859375\n",
      "saved model\n",
      "Epoch 30 : train_loss 5.38836168077257\n",
      "Epoch 30 : test_loss 5.339345581054688\n",
      "saved model\n",
      "Epoch 31 : train_loss 5.360910101996528\n",
      "Epoch 31 : test_loss 5.326525451660157\n",
      "saved model\n",
      "Epoch 32 : train_loss 5.3343365342881945\n",
      "Epoch 32 : test_loss 5.281244506835938\n",
      "saved model\n",
      "Epoch 33 : train_loss 5.305917249891493\n",
      "Epoch 33 : test_loss 5.241522705078125\n",
      "saved model\n",
      "Epoch 34 : train_loss 5.274644829644097\n",
      "Epoch 34 : test_loss 5.234727111816406\n",
      "saved model\n",
      "Epoch 35 : train_loss 5.248678344726563\n",
      "Epoch 35 : test_loss 5.202351379394531\n",
      "saved model\n",
      "Epoch 36 : train_loss 5.222060397677952\n",
      "Epoch 36 : test_loss 5.170845520019531\n",
      "saved model\n",
      "Epoch 37 : train_loss 5.201408298068577\n",
      "Epoch 37 : test_loss 5.163538818359375\n",
      "saved model\n",
      "Epoch 38 : train_loss 5.178807169596354\n",
      "Epoch 38 : test_loss 5.127799743652344\n",
      "saved model\n",
      "Epoch 39 : train_loss 5.1491304660373265\n",
      "Epoch 39 : test_loss 5.0957511596679685\n",
      "saved model\n",
      "Epoch 40 : train_loss 5.129150105794271\n",
      "Epoch 40 : test_loss 5.087947143554688\n",
      "saved model\n",
      "Epoch 41 : train_loss 5.102618855794271\n",
      "Epoch 41 : test_loss 5.054193969726563\n",
      "saved model\n",
      "Epoch 42 : train_loss 5.086833062065972\n",
      "Epoch 42 : test_loss 5.028689575195313\n",
      "saved model\n",
      "Epoch 43 : train_loss 5.0568512641059025\n",
      "Epoch 43 : test_loss 5.022043334960937\n",
      "saved model\n",
      "Epoch 44 : train_loss 5.042074340820313\n",
      "Epoch 44 : test_loss 4.975584533691406\n",
      "saved model\n",
      "Epoch 45 : train_loss 5.020599324544271\n",
      "Epoch 45 : test_loss 4.97422314453125\n",
      "saved model\n",
      "Epoch 46 : train_loss 4.999731580946181\n",
      "Epoch 46 : test_loss 4.934752502441406\n",
      "saved model\n",
      "Epoch 47 : train_loss 4.978871595594618\n",
      "Epoch 47 : test_loss 4.920059265136719\n",
      "saved model\n",
      "Epoch 48 : train_loss 4.954181423611111\n",
      "Epoch 48 : test_loss 4.910774780273438\n",
      "saved model\n",
      "Epoch 49 : train_loss 4.938585856119792\n",
      "Epoch 49 : test_loss 4.892331420898437\n",
      "saved model\n",
      "Epoch 50 : train_loss 4.914813598632812\n",
      "Epoch 50 : test_loss 4.852761352539063\n",
      "Epoch 51 : train_loss 4.897272935655382\n",
      "Epoch 51 : test_loss 4.8564755249023435\n",
      "saved model\n",
      "Epoch 52 : train_loss 4.872833414713542\n",
      "Epoch 52 : test_loss 4.817047485351562\n",
      "saved model\n",
      "Epoch 53 : train_loss 4.854080268012153\n",
      "Epoch 53 : test_loss 4.792959808349609\n",
      "Epoch 54 : train_loss 4.83756305609809\n",
      "Epoch 54 : test_loss 4.804141357421875\n",
      "saved model\n",
      "Epoch 55 : train_loss 4.81877057562934\n",
      "Epoch 55 : test_loss 4.760329315185547\n",
      "saved model\n",
      "Epoch 56 : train_loss 4.797111206054687\n",
      "Epoch 56 : test_loss 4.7265146484375\n",
      "saved model\n",
      "Epoch 57 : train_loss 4.776022827148437\n",
      "Epoch 57 : test_loss 4.713508911132813\n",
      "saved model\n",
      "Epoch 58 : train_loss 4.7560013970269095\n",
      "Epoch 58 : test_loss 4.677101501464843\n",
      "Epoch 59 : train_loss 4.733017903645833\n",
      "Epoch 59 : test_loss 4.685810729980469\n",
      "saved model\n",
      "Epoch 60 : train_loss 4.712786159939236\n",
      "Epoch 60 : test_loss 4.660309692382812\n",
      "saved model\n",
      "Epoch 61 : train_loss 4.683804063585069\n",
      "Epoch 61 : test_loss 4.631375579833985\n",
      "saved model\n",
      "Epoch 62 : train_loss 4.670014458550347\n",
      "Epoch 62 : test_loss 4.6241739501953125\n",
      "saved model\n",
      "Epoch 63 : train_loss 4.652727376302083\n",
      "Epoch 63 : test_loss 4.6054969482421875\n",
      "saved model\n",
      "Epoch 64 : train_loss 4.629263088650173\n",
      "Epoch 64 : test_loss 4.59204931640625\n",
      "saved model\n",
      "Epoch 65 : train_loss 4.6129542507595485\n",
      "Epoch 65 : test_loss 4.56302474975586\n",
      "saved model\n",
      "Epoch 66 : train_loss 4.5939432508680556\n",
      "Epoch 66 : test_loss 4.537766906738281\n",
      "saved model\n",
      "Epoch 67 : train_loss 4.571530571831597\n",
      "Epoch 67 : test_loss 4.531258972167969\n",
      "saved model\n",
      "Epoch 68 : train_loss 4.554575520833334\n",
      "Epoch 68 : test_loss 4.487057434082031\n",
      "Epoch 69 : train_loss 4.531983452690972\n",
      "Epoch 69 : test_loss 4.490962768554687\n",
      "saved model\n",
      "Epoch 70 : train_loss 4.511565443250868\n",
      "Epoch 70 : test_loss 4.466605590820312\n",
      "saved model\n",
      "Epoch 71 : train_loss 4.489916558159722\n",
      "Epoch 71 : test_loss 4.4521441040039065\n",
      "saved model\n",
      "Epoch 72 : train_loss 4.4748792453342014\n",
      "Epoch 72 : test_loss 4.438979736328125\n",
      "saved model\n",
      "Epoch 73 : train_loss 4.4528086615668405\n",
      "Epoch 73 : test_loss 4.3835947265625\n",
      "Epoch 74 : train_loss 4.439323391384549\n",
      "Epoch 74 : test_loss 4.386327911376953\n",
      "saved model\n",
      "Epoch 75 : train_loss 4.4079137505425345\n",
      "Epoch 75 : test_loss 4.372431701660156\n",
      "saved model\n",
      "Epoch 76 : train_loss 4.394118082682292\n",
      "Epoch 76 : test_loss 4.343607543945312\n",
      "saved model\n",
      "Epoch 77 : train_loss 4.375283203125\n",
      "Epoch 77 : test_loss 4.331488464355469\n",
      "saved model\n",
      "Epoch 78 : train_loss 4.358471530490451\n",
      "Epoch 78 : test_loss 4.31808837890625\n",
      "saved model\n",
      "Epoch 79 : train_loss 4.338604248046875\n",
      "Epoch 79 : test_loss 4.293860778808594\n",
      "saved model\n",
      "Epoch 80 : train_loss 4.319032335069444\n",
      "Epoch 80 : test_loss 4.271803314208984\n",
      "saved model\n",
      "Epoch 81 : train_loss 4.299650838216146\n",
      "Epoch 81 : test_loss 4.263816284179687\n",
      "saved model\n",
      "Epoch 82 : train_loss 4.280524820963541\n",
      "Epoch 82 : test_loss 4.222108337402344\n",
      "Epoch 83 : train_loss 4.257025227864584\n",
      "Epoch 83 : test_loss 4.222325439453125\n",
      "saved model\n",
      "Epoch 84 : train_loss 4.229832817925347\n",
      "Epoch 84 : test_loss 4.200834411621094\n",
      "saved model\n",
      "Epoch 85 : train_loss 4.216466430664062\n",
      "Epoch 85 : test_loss 4.171488342285156\n",
      "saved model\n",
      "Epoch 86 : train_loss 4.19564885796441\n",
      "Epoch 86 : test_loss 4.14827978515625\n",
      "saved model\n",
      "Epoch 87 : train_loss 4.178304050021701\n",
      "Epoch 87 : test_loss 4.142461975097656\n",
      "saved model\n",
      "Epoch 88 : train_loss 4.156284749348958\n",
      "Epoch 88 : test_loss 4.1319242858886716\n",
      "saved model\n",
      "Epoch 89 : train_loss 4.134564860026042\n",
      "Epoch 89 : test_loss 4.089372253417968\n",
      "saved model\n",
      "Epoch 90 : train_loss 4.113471801757813\n",
      "Epoch 90 : test_loss 4.081752655029297\n",
      "saved model\n",
      "Epoch 91 : train_loss 4.09180419921875\n",
      "Epoch 91 : test_loss 4.052496551513672\n",
      "saved model\n",
      "Epoch 92 : train_loss 4.075579535590278\n",
      "Epoch 92 : test_loss 4.039272521972657\n",
      "saved model\n",
      "Epoch 93 : train_loss 4.051066297743056\n",
      "Epoch 93 : test_loss 3.995702392578125\n",
      "Epoch 94 : train_loss 4.0367131618923615\n",
      "Epoch 94 : test_loss 3.99660302734375\n",
      "saved model\n",
      "Epoch 95 : train_loss 4.015146172417535\n",
      "Epoch 95 : test_loss 3.9740339050292968\n",
      "saved model\n",
      "Epoch 96 : train_loss 3.991103108723958\n",
      "Epoch 96 : test_loss 3.9491572265625\n",
      "saved model\n",
      "Epoch 97 : train_loss 3.9722901882595485\n",
      "Epoch 97 : test_loss 3.9424554138183594\n",
      "saved model\n",
      "Epoch 98 : train_loss 3.9539974229600694\n",
      "Epoch 98 : test_loss 3.9163240966796873\n",
      "saved model\n",
      "Epoch 99 : train_loss 3.9346048719618056\n",
      "Epoch 99 : test_loss 3.899346984863281\n",
      "saved model\n",
      "Epoch 100 : train_loss 3.9169605848524305\n",
      "Epoch 100 : test_loss 3.862615234375\n",
      "saved model\n",
      "Epoch 101 : train_loss 3.888676445855035\n",
      "Epoch 101 : test_loss 3.845377380371094\n",
      "saved model\n",
      "Epoch 102 : train_loss 3.8771333279079863\n",
      "Epoch 102 : test_loss 3.8326835327148436\n",
      "saved model\n",
      "Epoch 103 : train_loss 3.856186726888021\n",
      "Epoch 103 : test_loss 3.820976501464844\n",
      "saved model\n",
      "Epoch 104 : train_loss 3.8365052625868055\n",
      "Epoch 104 : test_loss 3.790930450439453\n",
      "saved model\n",
      "Epoch 105 : train_loss 3.816613972981771\n",
      "Epoch 105 : test_loss 3.7896184997558593\n",
      "saved model\n",
      "Epoch 106 : train_loss 3.798656032986111\n",
      "Epoch 106 : test_loss 3.7593074340820314\n",
      "saved model\n",
      "Epoch 107 : train_loss 3.7824576009114583\n",
      "Epoch 107 : test_loss 3.7482584228515625\n",
      "saved model\n",
      "Epoch 108 : train_loss 3.7608076985677084\n",
      "Epoch 108 : test_loss 3.721783630371094\n",
      "saved model\n",
      "Epoch 109 : train_loss 3.7380924207899304\n",
      "Epoch 109 : test_loss 3.7128181762695314\n",
      "saved model\n",
      "Epoch 110 : train_loss 3.7260272759331596\n",
      "Epoch 110 : test_loss 3.6778641357421873\n",
      "saved model\n",
      "Epoch 111 : train_loss 3.7006317409939236\n",
      "Epoch 111 : test_loss 3.673847961425781\n",
      "saved model\n",
      "Epoch 112 : train_loss 3.685844482421875\n",
      "Epoch 112 : test_loss 3.632650726318359\n",
      "saved model\n",
      "Epoch 113 : train_loss 3.6704947645399306\n",
      "Epoch 113 : test_loss 3.623637939453125\n",
      "saved model\n",
      "Epoch 114 : train_loss 3.6472408040364583\n",
      "Epoch 114 : test_loss 3.5991749572753906\n",
      "saved model\n",
      "Epoch 115 : train_loss 3.631375257703993\n",
      "Epoch 115 : test_loss 3.575924987792969\n",
      "saved model\n",
      "Epoch 116 : train_loss 3.60780224609375\n",
      "Epoch 116 : test_loss 3.5682894287109375\n",
      "saved model\n",
      "Epoch 117 : train_loss 3.5916828884548613\n",
      "Epoch 117 : test_loss 3.538868347167969\n",
      "Epoch 118 : train_loss 3.565729200575087\n",
      "Epoch 118 : test_loss 3.544878723144531\n",
      "saved model\n",
      "Epoch 119 : train_loss 3.550269015842014\n",
      "Epoch 119 : test_loss 3.507219085693359\n",
      "saved model\n",
      "Epoch 120 : train_loss 3.5331947292751735\n",
      "Epoch 120 : test_loss 3.497253723144531\n",
      "saved model\n",
      "Epoch 121 : train_loss 3.514469448513455\n",
      "Epoch 121 : test_loss 3.467075927734375\n",
      "saved model\n",
      "Epoch 122 : train_loss 3.493408901638455\n",
      "Epoch 122 : test_loss 3.444172119140625\n",
      "saved model\n",
      "Epoch 123 : train_loss 3.468913784450955\n",
      "Epoch 123 : test_loss 3.443338653564453\n",
      "saved model\n",
      "Epoch 124 : train_loss 3.4504013671875\n",
      "Epoch 124 : test_loss 3.4073744812011717\n",
      "saved model\n",
      "Epoch 125 : train_loss 3.4315854424370658\n",
      "Epoch 125 : test_loss 3.3804837646484374\n",
      "saved model\n",
      "Epoch 126 : train_loss 3.4158455878363716\n",
      "Epoch 126 : test_loss 3.376550354003906\n",
      "saved model\n",
      "Epoch 127 : train_loss 3.391842753092448\n",
      "Epoch 127 : test_loss 3.3623936767578124\n",
      "saved model\n",
      "Epoch 128 : train_loss 3.3715743882921005\n",
      "Epoch 128 : test_loss 3.34539404296875\n",
      "saved model\n",
      "Epoch 129 : train_loss 3.3537286716037324\n",
      "Epoch 129 : test_loss 3.3137600402832033\n",
      "saved model\n",
      "Epoch 130 : train_loss 3.3364537692599825\n",
      "Epoch 130 : test_loss 3.3009757690429686\n",
      "saved model\n",
      "Epoch 131 : train_loss 3.3154047241210938\n",
      "Epoch 131 : test_loss 3.2825552368164064\n",
      "saved model\n",
      "Epoch 132 : train_loss 3.3011602851019965\n",
      "Epoch 132 : test_loss 3.243332489013672\n",
      "saved model\n",
      "Epoch 133 : train_loss 3.281098158094618\n",
      "Epoch 133 : test_loss 3.239656982421875\n",
      "saved model\n",
      "Epoch 134 : train_loss 3.256467732747396\n",
      "Epoch 134 : test_loss 3.211735290527344\n",
      "Epoch 135 : train_loss 3.235654439290365\n",
      "Epoch 135 : test_loss 3.2140662536621094\n",
      "saved model\n",
      "Epoch 136 : train_loss 3.220650187174479\n",
      "Epoch 136 : test_loss 3.1806593322753907\n",
      "saved model\n",
      "Epoch 137 : train_loss 3.193294250488281\n",
      "Epoch 137 : test_loss 3.164268768310547\n",
      "saved model\n",
      "Epoch 138 : train_loss 3.171140448676215\n",
      "Epoch 138 : test_loss 3.1551043395996095\n",
      "saved model\n",
      "Epoch 139 : train_loss 3.158549309624566\n",
      "Epoch 139 : test_loss 3.1233713989257814\n",
      "saved model\n",
      "Epoch 140 : train_loss 3.1418558281792537\n",
      "Epoch 140 : test_loss 3.091549133300781\n",
      "saved model\n",
      "Epoch 141 : train_loss 3.118827412923177\n",
      "Epoch 141 : test_loss 3.077988098144531\n",
      "saved model\n",
      "Epoch 142 : train_loss 3.1009768880208335\n",
      "Epoch 142 : test_loss 3.0581160278320314\n",
      "saved model\n",
      "Epoch 143 : train_loss 3.078728515625\n",
      "Epoch 143 : test_loss 3.0468960876464846\n",
      "saved model\n",
      "Epoch 144 : train_loss 3.0613256022135418\n",
      "Epoch 144 : test_loss 3.0134664306640624\n",
      "saved model\n",
      "Epoch 145 : train_loss 3.0446588270399304\n",
      "Epoch 145 : test_loss 3.0051109008789063\n",
      "saved model\n",
      "Epoch 146 : train_loss 3.0207313435872396\n",
      "Epoch 146 : test_loss 2.965625244140625\n",
      "Epoch 147 : train_loss 2.9970714518229165\n",
      "Epoch 147 : test_loss 2.9728748779296876\n",
      "saved model\n",
      "Epoch 148 : train_loss 2.98514446343316\n",
      "Epoch 148 : test_loss 2.94622509765625\n",
      "saved model\n",
      "Epoch 149 : train_loss 2.9669015502929685\n",
      "Epoch 149 : test_loss 2.9317807006835936\n",
      "saved model\n",
      "Epoch 150 : train_loss 2.94781103515625\n",
      "Epoch 150 : test_loss 2.9014820251464846\n",
      "saved model\n",
      "Epoch 151 : train_loss 2.9310414021809894\n",
      "Epoch 151 : test_loss 2.896230895996094\n",
      "saved model\n",
      "Epoch 152 : train_loss 2.9108822631835936\n",
      "Epoch 152 : test_loss 2.8622118225097655\n",
      "Epoch 153 : train_loss 2.897292032877604\n",
      "Epoch 153 : test_loss 2.8689979248046873\n",
      "saved model\n",
      "Epoch 154 : train_loss 2.870765672471788\n",
      "Epoch 154 : test_loss 2.839062713623047\n",
      "saved model\n",
      "Epoch 155 : train_loss 2.8539972330729166\n",
      "Epoch 155 : test_loss 2.8287463073730468\n",
      "saved model\n",
      "Epoch 156 : train_loss 2.83060055202908\n",
      "Epoch 156 : test_loss 2.8044584655761717\n",
      "saved model\n",
      "Epoch 157 : train_loss 2.818708970811632\n",
      "Epoch 157 : test_loss 2.774691619873047\n",
      "saved model\n",
      "Epoch 158 : train_loss 2.795166042751736\n",
      "Epoch 158 : test_loss 2.763650604248047\n",
      "saved model\n",
      "Epoch 159 : train_loss 2.7766874457465276\n",
      "Epoch 159 : test_loss 2.742547332763672\n",
      "Epoch 160 : train_loss 2.763042914496528\n",
      "Epoch 160 : test_loss 2.7437640380859376\n",
      "saved model\n",
      "Epoch 161 : train_loss 2.7418529120551214\n",
      "Epoch 161 : test_loss 2.7012645568847655\n",
      "saved model\n",
      "Epoch 162 : train_loss 2.7215497029622395\n",
      "Epoch 162 : test_loss 2.681814208984375\n",
      "saved model\n",
      "Epoch 163 : train_loss 2.7104870334201387\n",
      "Epoch 163 : test_loss 2.6743424072265625\n",
      "saved model\n",
      "Epoch 164 : train_loss 2.6909060736762154\n",
      "Epoch 164 : test_loss 2.638776580810547\n",
      "saved model\n",
      "Epoch 165 : train_loss 2.672372829861111\n",
      "Epoch 165 : test_loss 2.636204406738281\n",
      "saved model\n",
      "Epoch 166 : train_loss 2.6475499538845484\n",
      "Epoch 166 : test_loss 2.6192796020507814\n",
      "saved model\n",
      "Epoch 167 : train_loss 2.6339014417860245\n",
      "Epoch 167 : test_loss 2.597879913330078\n",
      "saved model\n",
      "Epoch 168 : train_loss 2.6120607435438368\n",
      "Epoch 168 : test_loss 2.5655216064453126\n",
      "saved model\n",
      "Epoch 169 : train_loss 2.601729234483507\n",
      "Epoch 169 : test_loss 2.5540758056640627\n",
      "saved model\n",
      "Epoch 170 : train_loss 2.5767474500868057\n",
      "Epoch 170 : test_loss 2.542305755615234\n",
      "saved model\n",
      "Epoch 171 : train_loss 2.5568943956163195\n",
      "Epoch 171 : test_loss 2.5135252380371096\n",
      "saved model\n",
      "Epoch 172 : train_loss 2.535461113823785\n",
      "Epoch 172 : test_loss 2.500561065673828\n",
      "saved model\n",
      "Epoch 173 : train_loss 2.5205767822265623\n",
      "Epoch 173 : test_loss 2.4824505615234376\n",
      "saved model\n",
      "Epoch 174 : train_loss 2.5011297946506077\n",
      "Epoch 174 : test_loss 2.476700897216797\n",
      "saved model\n",
      "Epoch 175 : train_loss 2.483711188422309\n",
      "Epoch 175 : test_loss 2.455886169433594\n",
      "saved model\n",
      "Epoch 176 : train_loss 2.4781646525065106\n",
      "Epoch 176 : test_loss 2.4387515563964843\n",
      "saved model\n",
      "Epoch 177 : train_loss 2.4544959513346356\n",
      "Epoch 177 : test_loss 2.4189451293945314\n",
      "saved model\n",
      "Epoch 178 : train_loss 2.4364423014322916\n",
      "Epoch 178 : test_loss 2.3982807006835936\n",
      "Epoch 179 : train_loss 2.4228131578233505\n",
      "Epoch 179 : test_loss 2.4066910400390626\n",
      "saved model\n",
      "Epoch 180 : train_loss 2.4006764594184027\n",
      "Epoch 180 : test_loss 2.357205047607422\n",
      "saved model\n",
      "Epoch 181 : train_loss 2.3790251057942706\n",
      "Epoch 181 : test_loss 2.3384225463867185\n",
      "Epoch 182 : train_loss 2.3580319010416666\n",
      "Epoch 182 : test_loss 2.3417115783691407\n",
      "saved model\n",
      "Epoch 183 : train_loss 2.353094190809462\n",
      "Epoch 183 : test_loss 2.328990997314453\n",
      "saved model\n",
      "Epoch 184 : train_loss 2.334828877766927\n",
      "Epoch 184 : test_loss 2.3205633850097658\n",
      "saved model\n",
      "Epoch 185 : train_loss 2.3266185370551216\n",
      "Epoch 185 : test_loss 2.2712805633544924\n",
      "saved model\n",
      "Epoch 186 : train_loss 2.2951060791015623\n",
      "Epoch 186 : test_loss 2.270514862060547\n",
      "saved model\n",
      "Epoch 187 : train_loss 2.2823744710286458\n",
      "Epoch 187 : test_loss 2.2409954833984376\n",
      "Epoch 188 : train_loss 2.2791655815972223\n",
      "Epoch 188 : test_loss 2.253630844116211\n",
      "saved model\n",
      "Epoch 189 : train_loss 2.2577393391927085\n",
      "Epoch 189 : test_loss 2.215369354248047\n",
      "saved model\n",
      "Epoch 190 : train_loss 2.2290134616427952\n",
      "Epoch 190 : test_loss 2.202806121826172\n",
      "saved model\n",
      "Epoch 191 : train_loss 2.214248514811198\n",
      "Epoch 191 : test_loss 2.194218566894531\n",
      "saved model\n",
      "Epoch 192 : train_loss 2.208559875488281\n",
      "Epoch 192 : test_loss 2.1678665466308593\n",
      "saved model\n",
      "Epoch 193 : train_loss 2.1948822564019097\n",
      "Epoch 193 : test_loss 2.1631932067871094\n",
      "saved model\n",
      "Epoch 194 : train_loss 2.1727960205078123\n",
      "Epoch 194 : test_loss 2.1453809204101564\n",
      "saved model\n",
      "Epoch 195 : train_loss 2.1405906168619793\n",
      "Epoch 195 : test_loss 2.112384490966797\n",
      "Epoch 196 : train_loss 2.140663330078125\n",
      "Epoch 196 : test_loss 2.1210294342041016\n",
      "Epoch 197 : train_loss 2.1455716417100694\n",
      "Epoch 197 : test_loss 2.1337486572265627\n",
      "saved model\n",
      "Epoch 198 : train_loss 2.1319680921766495\n",
      "Epoch 198 : test_loss 2.0837838592529296\n",
      "saved model\n",
      "Epoch 199 : train_loss 2.107608201768663\n",
      "Epoch 199 : test_loss 2.065306182861328\n",
      "saved model\n",
      "Epoch 200 : train_loss 2.0714534776475695\n",
      "Epoch 200 : test_loss 2.059202896118164\n",
      "saved model\n",
      "Epoch 201 : train_loss 2.074162116156684\n",
      "Epoch 201 : test_loss 2.0224615478515626\n",
      "Epoch 202 : train_loss 2.0885601806640626\n",
      "Epoch 202 : test_loss 2.055315673828125\n",
      "saved model\n",
      "Epoch 203 : train_loss 2.048717861599392\n",
      "Epoch 203 : test_loss 2.0135741577148436\n",
      "saved model\n",
      "Epoch 204 : train_loss 2.0150025634765627\n",
      "Epoch 204 : test_loss 1.9602001190185547\n",
      "Epoch 205 : train_loss 2.010727735731337\n",
      "Epoch 205 : test_loss 1.9931161499023438\n",
      "Epoch 206 : train_loss 2.028687255859375\n",
      "Epoch 206 : test_loss 1.9984998474121094\n",
      "Epoch 207 : train_loss 2.0346331854926216\n",
      "Epoch 207 : test_loss 1.9912431335449219\n",
      "Epoch 208 : train_loss 2.0166028442382813\n",
      "Epoch 208 : test_loss 1.9737102203369141\n",
      "saved model\n",
      "Epoch 209 : train_loss 1.9872753974066841\n",
      "Epoch 209 : test_loss 1.9535902862548828\n",
      "saved model\n",
      "Epoch 210 : train_loss 1.9539431627061632\n",
      "Epoch 210 : test_loss 1.886985107421875\n",
      "Epoch 211 : train_loss 1.9346436292860243\n",
      "Epoch 211 : test_loss 1.9370212707519532\n",
      "Epoch 212 : train_loss 1.9413213568793404\n",
      "Epoch 212 : test_loss 1.9202866973876953\n",
      "Epoch 213 : train_loss 1.967573221842448\n",
      "Epoch 213 : test_loss 1.9522445068359375\n",
      "Epoch 214 : train_loss 1.9454024590386285\n",
      "Epoch 214 : test_loss 1.8976558227539062\n",
      "saved model\n",
      "Epoch 215 : train_loss 1.8941517401801216\n",
      "Epoch 215 : test_loss 1.8616910552978516\n",
      "saved model\n",
      "Epoch 216 : train_loss 1.839049058702257\n",
      "Epoch 216 : test_loss 1.8088938903808593\n",
      "Epoch 217 : train_loss 1.8327859836154514\n",
      "Epoch 217 : test_loss 1.8307400665283202\n",
      "Epoch 218 : train_loss 1.8494613579644097\n",
      "Epoch 218 : test_loss 1.8389190521240235\n",
      "Epoch 219 : train_loss 1.8835728420681424\n",
      "Epoch 219 : test_loss 1.8579474487304688\n",
      "Epoch 220 : train_loss 1.8657754991319444\n",
      "Epoch 220 : test_loss 1.8432875061035157\n",
      "saved model\n",
      "Epoch 221 : train_loss 1.8305347561306424\n",
      "Epoch 221 : test_loss 1.7943992919921874\n",
      "Epoch 222 : train_loss 1.8365752393934462\n",
      "Epoch 222 : test_loss 1.810861343383789\n",
      "Epoch 223 : train_loss 1.861498514811198\n",
      "Epoch 223 : test_loss 1.819461151123047\n",
      "saved model\n",
      "Epoch 224 : train_loss 1.849966288248698\n",
      "Epoch 224 : test_loss 1.7755377502441407\n",
      "saved model\n",
      "Epoch 225 : train_loss 1.7788152838812934\n",
      "Epoch 225 : test_loss 1.7124056854248046\n",
      "saved model\n",
      "Epoch 226 : train_loss 1.7229340074327257\n",
      "Epoch 226 : test_loss 1.6765300903320313\n",
      "Epoch 227 : train_loss 1.7066937696668836\n",
      "Epoch 227 : test_loss 1.7268336181640624\n",
      "Epoch 228 : train_loss 1.7225606045193143\n",
      "Epoch 228 : test_loss 1.7334063720703126\n",
      "Epoch 229 : train_loss 1.745870361328125\n",
      "Epoch 229 : test_loss 1.7459917907714844\n",
      "Epoch 230 : train_loss 1.7486871236165364\n",
      "Epoch 230 : test_loss 1.698583770751953\n",
      "Epoch 231 : train_loss 1.720929243299696\n",
      "Epoch 231 : test_loss 1.7144212799072265\n",
      "Epoch 232 : train_loss 1.698777570936415\n",
      "Epoch 232 : test_loss 1.71317529296875\n",
      "Epoch 233 : train_loss 1.7191531711154513\n",
      "Epoch 233 : test_loss 1.6998035888671874\n",
      "Epoch 234 : train_loss 1.7430398796929254\n",
      "Epoch 234 : test_loss 1.7146191253662109\n",
      "Epoch 235 : train_loss 1.7501380004882812\n",
      "Epoch 235 : test_loss 1.681622039794922\n",
      "Epoch 236 : train_loss 1.7132865905761718\n",
      "Epoch 236 : test_loss 1.6962299041748048\n",
      "saved model\n",
      "Epoch 237 : train_loss 1.6731929490831163\n",
      "Epoch 237 : test_loss 1.5899175720214844\n",
      "Epoch 238 : train_loss 1.656246348063151\n",
      "Epoch 238 : test_loss 1.6012441864013671\n",
      "Epoch 239 : train_loss 1.6737737087673612\n",
      "Epoch 239 : test_loss 1.6723012390136718\n",
      "Epoch 240 : train_loss 1.683462880452474\n",
      "Epoch 240 : test_loss 1.6398321838378906\n",
      "Epoch 241 : train_loss 1.6668861253526475\n",
      "Epoch 241 : test_loss 1.6299119415283203\n",
      "saved model\n",
      "Epoch 242 : train_loss 1.6324754503038195\n",
      "Epoch 242 : test_loss 1.5863521728515626\n",
      "saved model\n",
      "Epoch 243 : train_loss 1.5867535841200087\n",
      "Epoch 243 : test_loss 1.5659779052734375\n",
      "Epoch 244 : train_loss 1.5841317240397135\n",
      "Epoch 244 : test_loss 1.6005994873046876\n",
      "Epoch 245 : train_loss 1.6261895989312065\n",
      "Epoch 245 : test_loss 1.650930374145508\n",
      "Epoch 246 : train_loss 1.6887749532063803\n",
      "Epoch 246 : test_loss 1.6872313537597656\n",
      "Epoch 247 : train_loss 1.721828121609158\n",
      "Epoch 247 : test_loss 1.6864940490722655\n",
      "Epoch 248 : train_loss 1.6807829996744792\n",
      "Epoch 248 : test_loss 1.5943843383789063\n",
      "saved model\n",
      "Epoch 249 : train_loss 1.5929472283257378\n",
      "Epoch 249 : test_loss 1.547382568359375\n",
      "saved model\n",
      "Epoch 250 : train_loss 1.4978960537380643\n",
      "Epoch 250 : test_loss 1.4519043884277343\n",
      "Epoch 251 : train_loss 1.4775016513400607\n",
      "Epoch 251 : test_loss 1.4831827545166016\n",
      "Epoch 252 : train_loss 1.5272279527452257\n",
      "Epoch 252 : test_loss 1.5140535888671875\n",
      "Epoch 253 : train_loss 1.60914796617296\n",
      "Epoch 253 : test_loss 1.6143705749511719\n",
      "Epoch 254 : train_loss 1.6449155748155382\n",
      "Epoch 254 : test_loss 1.5916046752929687\n",
      "Epoch 255 : train_loss 1.624072041829427\n",
      "Epoch 255 : test_loss 1.5315573272705079\n",
      "Epoch 256 : train_loss 1.5438450113932292\n",
      "Epoch 256 : test_loss 1.4952475128173828\n",
      "Epoch 257 : train_loss 1.4963833584255641\n",
      "Epoch 257 : test_loss 1.4644485473632813\n",
      "Epoch 258 : train_loss 1.4906326836480035\n",
      "Epoch 258 : test_loss 1.5022691192626954\n",
      "Epoch 259 : train_loss 1.5461618414984808\n",
      "Epoch 259 : test_loss 1.5014277191162109\n",
      "Epoch 260 : train_loss 1.5887389763726127\n",
      "Epoch 260 : test_loss 1.6098941040039063\n",
      "Epoch 261 : train_loss 1.6089966871473524\n",
      "Epoch 261 : test_loss 1.6162607879638673\n",
      "Epoch 262 : train_loss 1.6170309143066406\n",
      "Epoch 262 : test_loss 1.586380615234375\n"
     ]
    }
   ],
   "source": [
    "# Now create a dataloader and train the flows\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "model = my_model()\n",
    "model.cuda()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                       lr=1e-5, amsgrad=True)\n",
    "scheduler = ReduceLROnPlateau(optimizer,'min')\n",
    "\n",
    "lr = []\n",
    "losses = []\n",
    "\n",
    "\n",
    "n_train = 9000\n",
    "n_test = N - n_train\n",
    "data_train = TensorDataset(x[:n_train], y[:n_train])\n",
    "data_test = TensorDataset(x[n_train:], y[n_train:])\n",
    "train_loader = DataLoader(data_train, 300)\n",
    "test_loader = DataLoader(data_test, 300, shuffle=False)\n",
    "\n",
    "best_test_loss = np.inf\n",
    "for epoch in range(1000):\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for data_ in train_loader:\n",
    "        data_ = [d.cuda() for d in data_]\n",
    "        loss,dict = model.compute_kld(data_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    test_loss = 0\n",
    "    model.eval()\n",
    "    for data_ in test_loader:\n",
    "        data_ = [d.cuda() for d in data_]\n",
    "        with torch.no_grad():\n",
    "            loss,dict = model.compute_kld(data_)\n",
    "            test_loss += loss.item()\n",
    "    if test_loss < best_test_loss:\n",
    "        print('saved model')\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "        best_test_loss = test_loss  \n",
    "    scheduler.step(test_loss)\n",
    "    lr.append(optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "    losses.append(test_loss)\n",
    "    print(f'Epoch {epoch} : train_loss {train_loss/len(data_train)}')\n",
    "    print(f'Epoch {epoch} : test_loss {test_loss/len(data_test)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.plot(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the learned flows \n",
    "\n",
    "model = my_model()\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "idx = 0\n",
    "z_simulated_y = model.sample_from_y(y[idx], K = 500).detach().cpu()\n",
    "z_simulated_x = model.sample_from_x(x[idx], K = 500).detach().cpu()\n",
    "\n",
    "true_z_x = sample_from_uni_posterior_x(x[idx], K=500).detach().cpu()\n",
    "true_z_y = sample_from_uni_posterior_y(y[idx], K=500).detach().cpu()\n",
    "print(true_z_x.shape)\n",
    "\n",
    "print(x[idx],y[idx])\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (7,7))\n",
    "ax.scatter(z_simulated_x[:,0],z_simulated_x[:,1])\n",
    "ax.scatter(z_simulated_y[:,0],z_simulated_y[:,1])\n",
    "\n",
    "ax.scatter(true_z_x[0],true_z_x[1])\n",
    "ax.scatter(true_z_y[0],true_z_y[1])\n",
    "\n",
    "ax.set_xlim([-10,10])\n",
    "ax.set_ylim([-10,10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('myenv38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4e60172799112451e675ed8f39ac039c9c5784e1c33f4b2379e9e5e54444ff0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
